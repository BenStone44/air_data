{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset info and constants\n",
    "file_dir = \"china_isd_lite_2020\"\n",
    "# list head\n",
    "year = 0\n",
    "month = 1\n",
    "day = 2\n",
    "hour = 3\n",
    "air_temperature = 4\n",
    "dew_point_temperature = 5\n",
    "sea_level_pressure = 6\n",
    "wind_direction = 7\n",
    "wind_speed_rate = 8\n",
    "sky_condition_total_coverage_code = 9\n",
    "### sky_condition_total_coverage_code\n",
    "## DOMAIN:\n",
    "#  0: None, SKC or CLR\n",
    "#  1: One okta - 1/10 or less but not zero\n",
    "#  2: Two oktas - 2/10 - 3/10, or FEW\n",
    "#  3: Three oktas - 4/10\n",
    "#  4: Four oktas - 5/10, or SCT\n",
    "#  5: Five oktas - 6/10\n",
    "#  6: Six oktas - 7/10 - 8/10\n",
    "#  7: Seven oktas - 9/10 or more but not 10/10, or BKN\n",
    "#  8: Eight oktas - 10/10, or OVC\n",
    "#  9: Sky obscured, or cloud amount cannot be estimated\n",
    "# 10: Partial obscuration\n",
    "# 11: Thin scattered\n",
    "# 12: Scattered\n",
    "# 13: Dark scattered\n",
    "# 14: Thin broken\n",
    "# 15: Broken\n",
    "# 16: Dark broken\n",
    "# 17: Thin overcast\n",
    "# 18: Overcast\n",
    "# 19: Dark overcast\n",
    "liquid_precipitation_pepth_dimension_1_hour = 10\n",
    "liquid_precipitation_pepth_dimension_6_hour = 11\n",
    "\n",
    "MISSING_VALUE = \"-9999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_area = air_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: read total stations' file\n",
    "\n",
    "total_stations = {}\n",
    "count_missing_total = 0\n",
    "for file_name in os.listdir(file_dir):\n",
    "  # obtain site_id by file_name\n",
    "  station_id = file_name.split(\"-\")[0]\n",
    "\n",
    "  file_object = open(file_dir + \"/\"+file_name, 'r')\n",
    "  station_val = []\n",
    "  station_missing_index = []\n",
    "  station_missing_count = 0\n",
    "  line_index = 0\n",
    "\n",
    "\n",
    "  while(True):\n",
    "    line = file_object.readline().split()\n",
    "    if(line):\n",
    "      if (line[selected_area]==MISSING_VALUE):\n",
    "        count_missing_total += 1\n",
    "        station_missing_count+=1\n",
    "        station_missing_index.append(line_index)\n",
    "      station_val.append(int(line[selected_area]))\n",
    "    else: \n",
    "      break\n",
    "    line_index+=1\n",
    "\n",
    "  \n",
    "  total_stations[station_id] = {\n",
    "    \"val\": station_val,\n",
    "    \"missing_count\": station_missing_count,\n",
    "    \"missing_index\": station_missing_index,\n",
    "  }\n",
    "\n",
    "  # next line output saved in missing count.txt\n",
    "  # print(site_id, site_missing_count, site_missing_index)\n",
    "\n",
    "# print(count_missing_total)\n",
    "# out_file = open(\"step1.json\", \"w\")\n",
    "# json.dump(total_stations, out_file)\n",
    "# out_file.close()\n",
    "\n",
    "### statistics\n",
    "# 415 sites\n",
    "# missing_value_count: 2306\n",
    "# each site missing saved in missing count.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: read stations' locations,  site_id-> [lat, lon] and station name\n",
    "\n",
    "df=pd.read_csv('isd-history.csv')\n",
    "df2 = df[['USAF', 'STATION NAME', 'LAT', 'LON']]\n",
    "\n",
    "staion_info_dict = {}\n",
    "valid_count = 0\n",
    "total_count=0\n",
    "for i, j in df2.iterrows():\n",
    "  total_count+=1\n",
    "  valid = (not pd.isnull(j['STATION NAME'])) & (\n",
    "      not pd.isnull(j['LON'])) & (not pd.isnull(j['LAT']))\n",
    "  if (valid):\n",
    "    valid_count+=1\n",
    "    staion_info_dict[j['USAF']]={\n",
    "        'name': j['STATION NAME'],\n",
    "        'lon': j['LON'],\n",
    "        'lat': j['LAT']\n",
    "    }\n",
    "\n",
    "print(total_count, valid_count)\n",
    "# out_file = open(\"step2.json\", \"w\")\n",
    "# json.dump(staion_info_dict, out_file)\n",
    "# out_file.close()\n",
    "\n",
    "### statistics\n",
    "# 29562 stations\n",
    "# valid: 28374\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: check china stations missing info -> all valid, filter station_info\n",
    "count = 0\n",
    "for station_id in total_stations:\n",
    "  if (station_id not in staion_info_dict) :\n",
    "    count+=1\n",
    "# print(count)\n",
    "# 0\n",
    "\n",
    "china_station_dict = {}\n",
    "for station_id in total_stations:\n",
    "  if (station_id in staion_info_dict) :\n",
    "    china_station_dict[station_id] = staion_info_dict[station_id]\n",
    "\n",
    "# print(china_station_dict)\n",
    "# out_file = open(\"step3.json\", \"w\")\n",
    "# json.dump(china_station_dict, out_file)\n",
    "# out_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: a function to display knn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "031e7f485cbd72ba10e92838a4b30eae994fe63573ff50f9f992a51da0e44f73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
